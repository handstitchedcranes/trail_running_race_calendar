import json
import os
import logging
from datetime import datetime, timedelta
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# --- Configuration ---
# Use environment variables or a config file in a real application
# For example, using environment variables:
SERVICE_ACCOUNT_FILE = os.environ.get('SERVICE_ACCOUNT_FILE', '/Users/cman/Desktop/hand_stitched_cranes/trail-running-race-calendar-163ec892e435.json')
CALENDAR_ID = os.environ.get('CALENDAR_ID', 'd5fbe1b8c27282a1f8b781db726404619d4a44a36d2e8f8c8976b4ed8d02f88c@group.calendar.google.com')
JSON_DATA_FILE = os.environ.get('JSON_DATA_FILE', '/Users/cman/Desktop/hand_stitched_cranes/dev/trail_running_race_calendar/races.json')
# Unique identifier prefix for events created by this script
# Helps in querying only the events managed by this script
EVENT_ID_PREFIX = "trailcal"

SCOPES = ['https://www.googleapis.com/auth/calendar']

# --- Logging Setup ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Helper Functions ---

def load_race_data(json_path):
    """Loads race data from the specified JSON file."""
    try:
        with open(json_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        logging.error(f"Error: JSON data file not found at {json_path}")
        return None
    except json.JSONDecodeError:
        logging.error(f"Error: Could not decode JSON from {json_path}")
        return None

def create_google_calendar_service():
    """Creates and returns an authenticated Google Calendar service object."""
    try:
        creds = service_account.Credentials.from_service_account_file(
            SERVICE_ACCOUNT_FILE, scopes=SCOPES)
        service = build('calendar', 'v3', credentials=creds)
        logging.info("Successfully authenticated and built Google Calendar service.")
        return service
    except FileNotFoundError:
        logging.error(f"Error: Service account file not found at {SERVICE_ACCOUNT_FILE}")
        return None
    except Exception as e:
        logging.error(f"Error creating Google Calendar service: {e}")
        return None

def generate_event_id(race_name, race_date_str):
    """Generates a predictable and safe ID for a Google Calendar event."""
    # Convert to lowercase and remove all non-alphanumeric characters
    sanitized_name = ''.join(filter(str.isalnum, race_name)).lower()
    date_part = race_date_str.split('T')[0].replace('-', '')
    
    # Convert any characters outside a-v to their position in alphabet (mod 22)
    # This ensures all characters are within a-v range
    converted_name = ''
    for c in sanitized_name:
        if c.isdigit():
            converted_name += c
        else:
            # Convert character to 0-based position in alphabet (a=0, b=1, etc)
            # Then take modulo 22 to ensure it maps to a-v range
            char_num = (ord(c) - ord('a')) % 22
            converted_name += chr(ord('a') + char_num)
    
    base_id = f"{EVENT_ID_PREFIX}{converted_name}{date_part}"
    return base_id[:1024]  # Max length for event ID is 1024 chars

def get_existing_events(service, calendar_id, time_min_str):
    """Retrieves existing events potentially managed by this script from the calendar."""
    existing_events = {}
    page_token = None
    try:
        while True:
            # Query events starting from a reasonable time window
            # Using sharedExtendedProperty or privateExtendedProperty is more robust
            # if you add custom properties during creation, but requires more setup.
            # Querying by ID prefix in the 'q' parameter isn't directly supported AFAIK.
            # So, we fetch recent/future events and filter locally.
            events_result = service.events().list(
                calendarId=calendar_id,
                pageToken=page_token,
                timeMin=time_min_str, # Limit search range e.g., start of current month
                maxResults=250,      # Adjust as needed
                singleEvents=True,   # Important for recurring events (though less likely here)
                orderBy='startTime'
            ).execute()
            
            events = events_result.get('items', [])
            for event in events:
                # Check if the event ID was likely generated by our script
                event_id = event.get('id')
                if event_id and event_id.startswith(EVENT_ID_PREFIX):
                     # Use the generated ID as the key for easy lookup
                     existing_events[event_id] = event 

            page_token = events_result.get('nextPageToken')
            if not page_token:
                break
        logging.info(f"Found {len(existing_events)} potentially relevant existing events.")
        return existing_events
    except HttpError as error:
        logging.error(f"An API error occurred while fetching events: {error}")
        return {} # Return empty dict on error


# --- Main Processing Logic ---

def sync_calendar():
    """Main function to sync races from JSON to Google Calendar."""
    service = create_google_calendar_service()
    if not service:
        return

    races = load_race_data(JSON_DATA_FILE)
    if not races:
        return

    # Determine time range for querying existing events (e.g., from start of current month)
    now = datetime.now().astimezone() # Use timezone-aware datetime
    start_of_month = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
    time_min_iso = start_of_month.isoformat() 
    
    existing_events = get_existing_events(service, CALENDAR_ID, time_min_iso)
    processed_event_ids = set()

    for race in races:
        try:
            # --- Basic Data Validation ---
            race_name = race.get('name')
            start_str = race.get('start_dateTime')
            end_str = race.get('end_dateTime')
            timezone = race.get('timeZone', 'UTC') # Default to UTC if not specified
            livestream = race.get('livestream_link', '')
            location = race.get('location', '')
            description_extra = race.get('description', '') # Additional details

            if not all([race_name, start_str, end_str, timezone]):
                logging.warning(f"Skipping race due to missing data: {race}")
                continue

            # --- Prepare Event Body ---
            event_id = generate_event_id(race_name, start_str)
            processed_event_ids.add(event_id)

            description_content = f"Trail Running Event: {race_name}"
            if livestream:
                description_content += f"\nLivestream: {livestream}"
            if description_extra:
                 description_content += f"\n{description_extra}"

            event_body = {
                'summary': race_name,
                'id': event_id, # Set the predictable ID
                'start': {
                    'dateTime': start_str,
                    'timeZone': timezone,
                },
                'end': {
                    'dateTime': end_str,
                    'timeZone': timezone,
                },
                'description': description_content,
                'location': location,
                # You can add extended properties for better tracking/querying
                # 'extendedProperties': {
                #     'private': {
                #         'source': 'trail-running-calendar-app',
                #         'race_id': race.get('unique_race_id') # If you have one in JSON
                #     }
                # }
            }

            # --- Check if Event Exists and Compare ---
            existing_event = existing_events.get(event_id)

            if existing_event:
                # Compare relevant fields (summary, start, end, description, location)
                # This comparison logic might need refinement based on what changes you expect
                needs_update = False
                if (existing_event.get('summary') != event_body['summary'] or
                    existing_event.get('start') != event_body['start'] or
                    existing_event.get('end') != event_body['end'] or
                    existing_event.get('description') != event_body['description'] or
                    existing_event.get('location') != event_body['location']):
                     needs_update = True
                
                if needs_update:
                    logging.info(f"Updating event: {race_name} (ID: {event_id})")
                    try:
                        updated_event = service.events().update(
                            calendarId=CALENDAR_ID, 
                            eventId=event_id, 
                            body=event_body
                        ).execute()
                        logging.info(f'Event updated: {updated_event.get("htmlLink")}')
                    except HttpError as error:
                        logging.error(f'Error updating event {event_id}: {error}')
                else:
                    logging.info(f"Event already exists and is up-to-date: {race_name} (ID: {event_id})")

            else:
                # --- Create New Event ---
                logging.info(f"Creating new event: {race_name} (ID: {event_id})")
                try:
                    created_event = service.events().insert(
                        calendarId=CALENDAR_ID, 
                        body=event_body
                    ).execute()
                    logging.info(f'Event created: {created_event.get("htmlLink")}')
                except HttpError as error:
                    # Handle potential ID conflicts explicitly (though unlikely with good ID generation)
                    if error.resp.status == 409: 
                         logging.warning(f"Event ID {event_id} conflict, likely already exists but wasn't fetched. Consider widening query range or using extended properties.")
                    else:
                         logging.error(f'Error creating event for {race_name}: {error}')

        except Exception as e:
            logging.error(f"Failed to process race {race.get('name', 'Unknown')}: {e}", exc_info=True)
            
    # --- Optional: Delete Orphaned Events ---
    # Events in the calendar (with our prefix) that are no longer in the JSON feed.
    # Be CAREFUL with automated deletion. Add checks/flags if needed.
    # Consider if races only get added, or if old ones should be removed.
    # If removing, only remove events within a specific future window maybe?
    
    # for event_id, event in existing_events.items():
    #     if event_id not in processed_event_ids:
    #         # Optional: Add checks, e.g., only delete if event start time is in the future
    #         event_start = datetime.fromisoformat(event['start'].get('dateTime'))
    #         if event_start > now: 
    #             logging.warning(f"Deleting orphaned event: {event.get('summary')} (ID: {event_id})")
    #             try:
    #                 service.events().delete(calendarId=CALENDAR_ID, eventId=event_id).execute()
    #             except HttpError as error:
    #                 logging.error(f"Error deleting event {event_id}: {error}")


if __name__ == '__main__':
    sync_calendar()
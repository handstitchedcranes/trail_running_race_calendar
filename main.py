import json
import os
import logging
from datetime import datetime, timedelta
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# --- Configuration ---
# Use environment variables or a config file in a real application
# For example, using environment variables:
SERVICE_ACCOUNT_FILE = os.environ.get('SERVICE_ACCOUNT_FILE', '/Users/cman/Desktop/hand_stitched_cranes/trail-running-race-calendar-163ec892e435.json')
CALENDAR_ID = os.environ.get('CALENDAR_ID', 'd5fbe1b8c27282a1f8b781db726404619d4a44a36d2e8f8c8976b4ed8d02f88c@group.calendar.google.com')
JSON_DATA_FILE = os.environ.get('JSON_DATA_FILE', '/Users/cman/Desktop/hand_stitched_cranes/dev/trail_running_race_calendar/races.json')
# Unique identifier prefix for events created by this script
# Helps in querying only the events managed by this script
EVENT_ID_PREFIX = "trailcal"

SCOPES = ['https://www.googleapis.com/auth/calendar']

# --- Logging Setup ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Helper Functions ---

def load_race_data(json_path):
    """Loads race data from the specified JSON file."""
    try:
        with open(json_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        logging.error(f"Error: JSON data file not found at {json_path}")
        return None
    except json.JSONDecodeError:
        logging.error(f"Error: Could not decode JSON from {json_path}")
        return None

def create_google_calendar_service():
    """Creates and returns an authenticated Google Calendar service object."""
    try:
        creds = service_account.Credentials.from_service_account_file(
            SERVICE_ACCOUNT_FILE, scopes=SCOPES)
        service = build('calendar', 'v3', credentials=creds)
        logging.info("Successfully authenticated and built Google Calendar service.")
        return service
    except FileNotFoundError:
        logging.error(f"Error: Service account file not found at {SERVICE_ACCOUNT_FILE}")
        return None
    except Exception as e:
        logging.error(f"Error creating Google Calendar service: {e}")
        return None

def generate_event_id(race_name, race_date_str):
    """Generates a predictable and safe ID for a Google Calendar event."""
    # Convert to lowercase and remove all non-alphanumeric characters
    sanitized_name = ''.join(filter(str.isalnum, race_name)).lower()
    date_part = race_date_str.split('T')[0].replace('-', '')
    
    # Convert any characters outside a-v to their position in alphabet (mod 22)
    # This ensures all characters are within a-v range
    converted_name = ''
    for c in sanitized_name:
        if c.isdigit():
            converted_name += c
        else:
            # Convert character to 0-based position in alphabet (a=0, b=1, etc)
            # Then take modulo 22 to ensure it maps to a-v range
            char_num = (ord(c) - ord('a')) % 22
            converted_name += chr(ord('a') + char_num)
    
    base_id = f"{EVENT_ID_PREFIX}{converted_name}{date_part}"
    return base_id[:1024]  # Max length for event ID is 1024 chars

def get_existing_events(service, calendar_id, time_min_str):
    """Retrieves existing events potentially managed by this script from the calendar."""
    existing_events = {}
    page_token = None
    try:
        while True:
            # Query events starting from a reasonable time window
            # Using sharedExtendedProperty or privateExtendedProperty is more robust
            # if you add custom properties during creation, but requires more setup.
            # Querying by ID prefix in the 'q' parameter isn't directly supported AFAIK.
            # So, we fetch recent/future events and filter locally.
            events_result = service.events().list(
                calendarId=calendar_id,
                pageToken=page_token,
                timeMin=time_min_str, # Limit search range e.g., start of current month
                maxResults=250,      # Adjust as needed
                singleEvents=True,   # Important for recurring events (though less likely here)
                orderBy='startTime'
            ).execute()
            
            events = events_result.get('items', [])
            for event in events:
                # Check if the event ID was likely generated by our script
                event_id = event.get('id')
                if event_id and event_id.startswith(EVENT_ID_PREFIX):
                     # Use the generated ID as the key for easy lookup
                     existing_events[event_id] = event 

            page_token = events_result.get('nextPageToken')
            if not page_token:
                break
        logging.info(f"Found {len(existing_events)} potentially relevant existing events.")
        return existing_events
    except HttpError as error:
        logging.error(f"An API error occurred while fetching events: {error}")
        return {} # Return empty dict on error

# --- Main Processing Logic ---

def sync_calendar():
    """Main function to sync races from JSON to Google Calendar."""
    service = create_google_calendar_service()
    if not service:
        return

    races = load_race_data(JSON_DATA_FILE)
    if not races:
        # Decide if you want to potentially delete EVERYTHING if JSON is missing/empty
        # For safety, we'll just return here.
        logging.error("Race data could not be loaded. Aborting sync to prevent accidental deletions.")
        return

    # Determine time range for querying existing events (e.g., from start of current month)
    # Use a date far in the past to ensure we catch all relevant prefixed events
    # or rely on the prefix filtering primarily. Let's start from beginning of year for safety.
    now = datetime.now().astimezone() # Use timezone-aware datetime
    start_of_year = now.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)
    time_min_iso = start_of_year.isoformat()

    existing_events = get_existing_events(service, CALENDAR_ID, time_min_iso)
    processed_event_ids = set() # Holds IDs generated from current JSON data

    # --- Process Races from JSON (Create/Update) ---
    for race in races:
        try:
            # --- Basic Data Validation ---
            race_name = race.get('name')
            start_str = race.get('start_dateTime')
            end_str = race.get('end_dateTime')
            timezone = race.get('timeZone', 'UTC') # Default to UTC if not specified
            livestream = race.get('livestream_link', '')
            location = race.get('location', '')
            description_extra = race.get('description', '') # Additional details

            if not all([race_name, start_str, end_str, timezone]):
                logging.warning(f"Skipping race due to missing data: {race}")
                continue

            # --- Prepare Event Body ---
            event_id = generate_event_id(race_name, start_str)
            processed_event_ids.add(event_id) # Add ID from JSON to our set

            description_content = f"Event: {race_name}"
            if livestream:
                description_content += f"\nLivestream: {livestream}"
            if description_extra:
                 description_content += f"\nDescription: {description_extra}"

            event_body = {
                'summary': race_name,
                'id': event_id, # Set the predictable ID
                'start': {
                    'dateTime': start_str,
                    'timeZone': timezone,
                },
                'end': {
                    'dateTime': end_str,
                    'timeZone': timezone,
                },
                'description': description_content,
                'location': location,
            }

            # --- Check if Event Exists and Compare ---
            existing_event = existing_events.get(event_id)

            if existing_event:
                # --- Update Logic ---
                needs_update = False
                # Simple comparison (more robust comparison might be needed)
                if (existing_event.get('summary') != event_body['summary'] or
                    existing_event.get('start') != event_body['start'] or # Compares dicts
                    existing_event.get('end') != event_body['end'] or     # Compares dicts
                    existing_event.get('description') != event_body['description'] or
                    existing_event.get('location') != event_body['location']):
                     needs_update = True

                if needs_update:
                    logging.info(f"Updating event: {race_name} (ID: {event_id})")
                    try:
                        updated_event = service.events().update(
                            calendarId=CALENDAR_ID,
                            eventId=event_id,
                            body=event_body
                        ).execute()
                        logging.info(f'Event updated: {updated_event.get("htmlLink")}')
                    except HttpError as error:
                        logging.error(f'Error updating event {event_id}: {error}')
                else:
                    logging.info(f"Event already exists and is up-to-date: {race_name} (ID: {event_id})")

            else:
                # --- Create New Event ---
                logging.info(f"Creating new event: {race_name} (ID: {event_id})")
                try:
                    created_event = service.events().insert(
                        calendarId=CALENDAR_ID,
                        body=event_body
                    ).execute()
                    logging.info(f'Event created: {created_event.get("htmlLink")}')
                except HttpError as error:
                    if error.resp.status == 409:
                         logging.warning(f"Event ID {event_id} conflict. Assuming it exists.")
                         # Add the ID from the conflict back into existing_events if needed,
                         # or just ensure it's treated as processed.
                         # Since it's already in processed_event_ids, it won't be deleted.
                    else:
                         logging.error(f'Error creating event for {race_name}: {error}')

        except Exception as e:
            logging.error(f"Failed to process race {race.get('name', 'Unknown')}: {e}", exc_info=True)

    # --- Delete Orphaned Events ---
    logging.info("Checking for orphaned events to delete...")
    deleted_count = 0
    # Iterate through the events we found *in the calendar*
    for event_id, event in existing_events.items():
        # Check if the ID from the calendar event is NOT in the set of IDs from the JSON file
        if event_id not in processed_event_ids:
            # This event is orphaned (exists in calendar, not in JSON)

            # Optional Safety Check: Only delete future events
            try:
                # Attempt to parse the start dateTime
                event_start_str = event.get('start', {}).get('dateTime')
                if event_start_str:
                    event_start = datetime.fromisoformat(event_start_str)
                    # Compare timezone-aware datetime objects
                    if event_start <= now:
                        logging.info(f"Skipping deletion of past/ongoing orphaned event: {event.get('summary')} (ID: {event_id})")
                        continue # Skip to the next event
                else:
                     # Handle cases where start dateTime might be missing (unlikely for inserted events)
                     logging.warning(f"Could not determine start time for event {event_id}; skipping deletion.")
                     continue

            except ValueError:
                logging.warning(f"Could not parse start dateTime '{event_start_str}' for event {event_id}; skipping deletion.")
                continue
            except Exception as e:
                 logging.error(f"Error checking start time for event {event_id}: {e}; skipping deletion.")
                 continue

            # Proceed with deletion
            logging.warning(f"Deleting orphaned event: {event.get('summary')} (ID: {event_id})")
            try:
                service.events().delete(calendarId=CALENDAR_ID, eventId=event_id).execute()
                deleted_count += 1
                # Small delay might be prudent if deleting many events rapidly, but usually not necessary
                # time.sleep(0.1)
            except HttpError as error:
                logging.error(f"Error deleting event {event_id}: {error}")
            except Exception as e:
                 logging.error(f"Unexpected error deleting event {event_id}: {e}")

    if deleted_count > 0:
        logging.info(f"Successfully deleted {deleted_count} orphaned events.")
    else:
        logging.info("No orphaned events found needing deletion (or only past events found).")

if __name__ == '__main__':
    sync_calendar()